{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba791a3-39dc-41ce-a764-1a495a5392bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from gtts import gTTS\n",
    "import speech_recognition as sr\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0eeaf83-b36a-4391-a396-652a01de4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-large-latest\",\n",
    "    temperature=0,\n",
    "    max_retries=2,\n",
    "    api_key=\"I5uzjp4ZXUioIEM7hdYgdJtpv4NUlWov\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b68dd131-e556-44ed-942b-6992618cec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening for your query...\")\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=5)\n",
    "            user_input = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {user_input}\")\n",
    "            return user_input\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I didn't catch that.\")\n",
    "            return None\n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"You took too long to respond.\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "946af7bd-33af-4f0f-8ed2-52d6d831f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_text(text):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(\"response.mp3\")\n",
    "    os.system(\"start response.mp3\" if os.name == \"nt\" else \"afplay response.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0cc4a0d-ef83-4873-a706-c947f0a759f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Software\\Anaconda\\envs\\predixion\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db = Chroma(persist_directory=\"./vector_db\", embedding_function=embedder)\n",
    "\n",
    "def get_response(user_query, doc_context):\n",
    "    llm_query_res_template = \"\"\"\n",
    "        Answer the question based on the context below. If the question cannot be answered using the information provided, reply with \"I don't know\". Also, make sure to answer the following questions considering the history of the conversation:\n",
    "        You are an intelligent virtual financial assistant for Predixion AI, directly engaging with customers about their loan repayments. Your role is to help manage their loan, facilitate payments, and answer financial questions in a clear, professional way. Communicate in a friendly, authoritative manner, addressing the customer directly (\"you\") with concise responses suitable for WhatsApp.\n",
    "        Make sure you communicate with the user in such a way that your response should always lead to payment collection.\n",
    "        Based on the user question, you should respond in a short way. Do not write much; it should be short and precise.\n",
    "\n",
    "        Instructions:\n",
    "        1. Use precise financial language and ensure clear, accurate information.\n",
    "        2. Facilitate payments: If the user is willing to pay the loan then please provide this link '''https://paymentUSER1UDN.com'''. Do not send the link until user requests or user wants to pay the loan.\n",
    "        3. Offer solutions: If the customer is struggling, provide options like grace periods, payment restructuring, or deadline extensions.\n",
    "        4. Keep responses short and to the point.\n",
    "        5. Ensure confidentiality and remind the customer to keep their payment details secure.\n",
    "        6. You can only extend the loan dates by 10 days if user requests for grace periods or deadline extensions.\n",
    "\n",
    "        Context: \"NONE\"\n",
    "        Question: {user_query}\n",
    "        Doc context: {doc_context}\n",
    "        Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_query_res_template = ChatPromptTemplate.from_template(llm_query_res_template)\n",
    "    llm_chain = prompt_query_res_template | llm | StrOutputParser()\n",
    "\n",
    "    '''response = llm_chain.stream({\n",
    "        \"user_query\": user_query,\n",
    "        \"context\": context,\n",
    "        \"doc_context\": doc_context,\n",
    "    })'''\n",
    "\n",
    "    response = ''.join([chunk for chunk in llm_chain.stream({\n",
    "        \"user_query\": user_query,\n",
    "        #\"context\": context,\n",
    "        \"doc_context\": doc_context,\n",
    "    })])\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc73ef18-99ab-4f06-b984-758715f73695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    print(\"Voice-enabled Chatbot is now running! Say 'quit' to exit.\")\n",
    "    while True:\n",
    "        user_query = recognize_speech()\n",
    "        if not user_query:\n",
    "            continue\n",
    "        if user_query.lower() == \"quit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        doc_context = '\\n'.join([doc.page_content for doc in db.max_marginal_relevance_search(user_query, k=2, fetch_k=10)])\n",
    "        response = get_response(user_query=user_query, doc_context=doc_context)\n",
    "\n",
    "        print(f'Bot: {response}')\n",
    "        speak_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "269b14fa-b5a3-4553-8395-5c5e85d85f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice-enabled Chatbot is now running! Say 'quit' to exit.\n",
      "Listening for your query...\n",
      "You said: hello I have a question\n",
      "Bot: Hello! I'm here to help with your loan repayment questions. What would you like to know?\n",
      "Listening for your query...\n",
      "You took too long to respond.\n",
      "Listening for your query...\n",
      "You said: give me a summary of the policies\n",
      "Bot: I don't know. Let's focus on your loan repayment. How can I assist you with your loan today?\n",
      "Listening for your query...\n",
      "You took too long to respond.\n",
      "Listening for your query...\n",
      "You said: quit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c766ca-8a57-4430-883c-3ddafb8b4a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
