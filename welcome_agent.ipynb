{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "991ecf01-122a-479c-9771-6acbcd249edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex\n",
    "import json\n",
    "import datetime, pytz\n",
    "import speech_recognition as sr\n",
    "\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import ToolMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.tools import tool, StructuredTool\n",
    "\n",
    "from db_search import get_info\n",
    "from text_to_speech import Text2Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a22eed41-2761-44a4-9886-eb2c588202fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-large-latest\",\n",
    "    temperature=0,\n",
    "    max_retries=2,\n",
    "    api_key=\"suFEUjmnfvT2AQSF5b6MQJ9NyZwDLsqG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f86f9c-9754-44e7-acd5-0afa2a63d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"_\"*100)\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=3000)\n",
    "            user_input = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {user_input}\")\n",
    "            return user_input\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.WaitTimeoutError:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce2fc7c7-f00f-433b-84b1-8fe3340d2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "\n",
    "def get_user_data() -> dict:\n",
    "    \"\"\"\n",
    "    Returns all information about the customer's loan.\n",
    "    \"\"\"\n",
    "    key = int(phone)\n",
    "    user_data = get_info(key)\n",
    "    return user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48234cc-d822-4749-aca1-bad669182100",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def current_date_time() -> dict:\n",
    "    '''\n",
    "    Returns the current server date and time in JSON format.\n",
    "    '''\n",
    "    now = datetime.datetime.now()\n",
    "    ist_timezone = pytz.timezone('Asia/Kolkata')\n",
    "    dt_ist = now.astimezone(ist_timezone)\n",
    "    time = dict()\n",
    "    time['day'] = dt_ist.strftime('%A')\n",
    "    time['month'] = dt_ist.strftime('%B')\n",
    "    time['date'] = dt_ist.strftime('%Y-%m-%d')\n",
    "    time['time'] = dt_ist.strftime('%H:%M')\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcbcae36-ec07-4434-8fef-28343d208645",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([get_user_data, current_date_time])\n",
    "\n",
    "tool_mapping = {\n",
    "    \"get_user_data\" : get_user_data,\n",
    "    \"current_date_time\" : current_date_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155d7d3b-8db5-4f15-b324-9bbaba03b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refresh convo.\n",
    "\n",
    "template = \"\"\"You are an intelligent virtual financial agent helping our customer {first_name} {last_name}.\n",
    "            Your role is to help manage the customer's loan repayment and answer their financial questions in a clear and precise way. \n",
    "\n",
    "            Instructions:\n",
    "            1. Use precise financial language and ensure clear, accurate information.\n",
    "            2. If the user is willing to pay the loan then please provide this link '''https://paymentUSER1UDN.com'''. Do not send the link until user requests or user wants to pay the loan.\n",
    "            3. If the customer is struggling, provide options like grace periods, payment restructuring, or deadline extensions considering their income, number of late repayment and loan amount yet to be repayed.\n",
    "            4. Keep responses short and to the point.\n",
    "            5. Ensure confidentiality and remind the customer to keep their payment details secure.\n",
    "            6. You can only extend the last loan repayment date by a maximum of 10 days if user requests for grace periods or deadline extensions considering their income, number of late repayment and loan amount yet to be repayed.\n",
    "            7. If the question cannot be answered using the information provided, reply with \"Sorry, but I am unable to answer this query\". \n",
    "            \n",
    "\"\"\"\n",
    "\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a356b5e6-336a-46f2-9eae-84d451bfc141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Software\\Anaconda\\envs\\voicecloning5\\lib\\site-packages\\TTS\\tts\\layers\\xtts\\xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "B:\\Software\\Anaconda\\envs\\voicecloning5\\lib\\site-packages\\TTS\\utils\\io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "speaker = Text2Speech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de25b4be-a7a8-4b0e-8167-47c47bbabacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_messages = [\n",
    "    SystemMessage(content=template),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{query}\")\n",
    "    #HumanMessage(content=\"{query}\")\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(template_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b5d77bf-5a45-490d-b247-2acfc96a214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone = 9804604602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a4a1399-6f2d-49ae-b268-96b9b80bc26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = get_info(phone)\n",
    "\n",
    "user_info = {\n",
    "    \"first_name\": user_data['first_name'],\n",
    "    \"last_name\": user_data['last_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6405a26a-35ab-44b2-8731-96d3b7cd5ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_template = template.format(**user_info)\n",
    "template_messages[0] = SystemMessage(content=formatted_template)\n",
    "prompt_template = ChatPromptTemplate.from_messages(template_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7be4bd7-e192-4559-bbe0-a54241554c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(text:str) -> str:\n",
    "    messages = prompt_template.format_messages(\n",
    "        chat_history=chat_history,\n",
    "        query = text\n",
    "    )\n",
    "    chat_history.append(HumanMessage(text))\n",
    "    \n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    chat_history.append(response)\n",
    "    \n",
    "    if response.tool_calls:\n",
    "        for tool_call in response.tool_calls:\n",
    "            tool = tool_mapping[tool_call['name']]\n",
    "            output = tool.invoke(tool_call['args'])\n",
    "            chat_history.append(ToolMessage(str(output), tool_call_id=tool_call['id']))\n",
    "            ai_says = llm_with_tools.invoke(chat_history)\n",
    "        chat_history.append(ai_says)\n",
    "    else:\n",
    "        ai_says = response\n",
    "\n",
    "    return ai_says.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2bf1a70-a960-4f06-baf6-c188bafdbee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  Hello Diya, I am here to talk about you loan repayment.\n",
      " > Text splitted to sentences.\n",
      "['Hello Diya, I am here to talk about you loan repayment.']\n",
      " > Processing time: 3.3000733852386475\n",
      " > Real-time factor: 0.5884219994866103\n",
      "Listening.....\n",
      "____________________________________________________________________________________________________\n",
      "You said: hello\n",
      "Bot:  Hello Diya,\n",
      "\n",
      "How can I assist you today with your loan management\n",
      " > Text splitted to sentences.\n",
      "['Hello Diya,', 'How can I assist you today with your loan management']\n",
      " > Processing time: 1.7292234897613525\n",
      " > Real-time factor: 0.23637037510686015\n",
      "Listening.....\n",
      "____________________________________________________________________________________________________\n",
      "You said: tell me my loan amount\n",
      "Bot:  Your loan amount is 36100.6 INR.\n",
      " > Text splitted to sentences.\n",
      "['Your loan amount is 36100.6 INR.']\n",
      " > Processing time: 1.5481913089752197\n",
      " > Real-time factor: 0.26195225876997846\n",
      "Listening.....\n",
      "____________________________________________________________________________________________________\n",
      "You said: and how much do I have to pay\n",
      "Bot:  You have to pay 25866.4 INR.\n",
      " > Text splitted to sentences.\n",
      "['You have to pay 25866.4 INR.']\n",
      " > Processing time: 1.608983039855957\n",
      " > Real-time factor: 0.24141314663053792\n",
      "Listening.....\n",
      "____________________________________________________________________________________________________\n",
      "You said: can I pay it right now\n",
      "Bot:  Sure, to pay your loan right now, please use this link:\n",
      "\n",
      "https:paymentUSER1UDN.com\n",
      "\n",
      "Please ensure to keep your payment details secure.\n",
      " > Text splitted to sentences.\n",
      "['Sure, to pay your loan right now, please use this link:', 'https:paymentUSER1UDN.com', 'Please ensure to keep your payment details secure.']\n",
      " > Processing time: 3.327916383743286\n",
      " > Real-time factor: 0.22800321980344104\n",
      "Listening.....\n",
      "____________________________________________________________________________________________________\n",
      "You said: ok thank you\n",
      "Bot:  You're welcome, Diya If you have any more questions or need further assistance, feel free to ask.\n",
      " > Text splitted to sentences.\n",
      "[\"You're welcome, Diya If you have any more questions or need further assistance, feel free to ask.\"]\n",
      " > Processing time: 2.7680914402008057\n",
      " > Real-time factor: 0.2435222480706502\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m cleaned_text \u001b[38;5;241m=\u001b[39m regex\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/@|!?]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, res)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBot: \u001b[39m\u001b[38;5;124m'\u001b[39m,cleaned_text)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeak\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mB:\\Projects\\Predixion_Internship\\Loan_Collection_Agent\\text_to_speech.py:18\u001b[0m, in \u001b[0;36mText2Speech.speak\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     16\u001b[0m sample_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts\u001b[38;5;241m.\u001b[39msynthesizer\u001b[38;5;241m.\u001b[39moutput_sample_rate\n\u001b[0;32m     17\u001b[0m sd\u001b[38;5;241m.\u001b[39mplay(wav, sample_rate)\n\u001b[1;32m---> 18\u001b[0m \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mB:\\Software\\Anaconda\\envs\\voicecloning5\\lib\\site-packages\\sounddevice.py:398\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(ignore_errors)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    395\u001b[0m \n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mB:\\Software\\Anaconda\\envs\\voicecloning5\\lib\\site-packages\\sounddevice.py:2645\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[1;34m(self, ignore_errors)\u001b[0m\n\u001b[0;32m   2639\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m \n\u001b[0;32m   2641\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m \n\u001b[0;32m   2643\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2645\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2646\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[1;32mB:\\Software\\Anaconda\\envs\\voicecloning5\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mB:\\Software\\Anaconda\\envs\\voicecloning5\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "welcome = AIMessage(content=f\"Hello {user_info['first_name']}, I am here to talk about you loan repayment.\")\n",
    "chat_history.append(welcome)\n",
    "print('Bot: ',welcome.content)\n",
    "speaker.speak(welcome.content)\n",
    "\n",
    "while True:\n",
    "    print(\"Listening.....\")\n",
    "    query = recognize_speech()\n",
    "    if query is not None:\n",
    "        if query.lower() == 'okay thank you' or 'ok thank you':\n",
    "            res = chat(query)\n",
    "            speaker.speak(res)\n",
    "            break\n",
    "        else:\n",
    "            res = chat(query)\n",
    "            cleaned_text = regex.sub(r'[\\/@|!?]', '', res)\n",
    "            print('Bot: ',cleaned_text)\n",
    "            speaker.speak(cleaned_text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6881c3-cc30-46d5-85a0-aec7227e2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    query = input('You Said:')\n",
    "    if query is not None:\n",
    "        if query.lower() == 'thanks':\n",
    "            res = chat(query)\n",
    "            speaker.speak(res)\n",
    "            break\n",
    "        else:\n",
    "            res = chat(query)\n",
    "            cleaned_text = regex.sub(r'[\\/@|!?]', '', res)\n",
    "            print('Bot: ',cleaned_text)\n",
    "            speaker.speak(cleaned_text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8ee6ab6-cb31-4216-8fba-5b6dd0edf3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " \"Hello Diya! I'm here to help with your loan management needs. How can I assist you today?\",\n",
       " 'thanks',\n",
       " \"You're welcome! If you have any questions or need assistance with your loan, feel free to ask.\",\n",
       " 'Hello',\n",
       " 'Hello Diya! How can I assist you with your loan today?',\n",
       " 'thanks',\n",
       " \"You're welcome, Diya! If you have more questions or need further assistance, just let me know.\",\n",
       " 'Hello',\n",
       " 'Hello Diya! How can I assist you with your loan today?',\n",
       " 'What amount do I have pending',\n",
       " '',\n",
       " \"{'first_name': 'Diya', 'last_name': 'Sharma', 'phone_no': 9804604602, 'gender': 'Female', 'income_in_inr': 380418.9, 'credit_score': 808, 'loan_type': 'Consumer Durable Loan', 'loan_amount': 36100.6, 'interest_rate': 12.4, 'process_fee': 361.0, 'installment': 6236.2, 'start_date': '2024-05-09', 'tenure': 6, 'balance_to_pay': 25866.4, 'payment_mode': 'Debit Card', 'late_payment': 0, 'last_date': '2024-08-03'}\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript = [convo.content for convo in chat_history]\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0372ee-bf83-42d6-9a77-148ec505965b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
